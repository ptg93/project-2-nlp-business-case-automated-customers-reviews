{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume: tokenization, lemmatization, vectorization are in place\n",
    "\n",
    "#assume: train, test set available\n",
    "# train = df['reviews.rating']\n",
    "# test = df['reviews.rating']\n",
    "\n",
    "#to push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Set the variable for the algo TO-DO: check what makes sense, naive or model variable\n",
    "# naive=MultinomialNB()\n",
    "\n",
    "# Creating model based on Multinomial Naive Bayes\n",
    "model = make_pipeline (TfidVectorizer(), MultinomialNB)\n",
    "\n",
    "# Training the model with the train data\n",
    "model.fit(traindataset, train['reviews.rating'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating labels for the test data\n",
    "labels = model.predict(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the Test Dataset\n",
    "test_transform= []\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = tfidfvector.transform(test_transform)\n",
    "predictions = naive.predict(test_dataset)\n",
    "\n",
    "# add gridsearchCV. we need to consider due to imbalance dataset: StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "matrix=confusion_matrix(test['reviews.rating'],predictions)\n",
    "print(matrix)\n",
    "score=accuracy_score(test['reviews.rating'],predictions)\n",
    "print(score)\n",
    "report=classification_report(test['reviews.rating'],predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(test.target, labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False\n",
    "    , xticklabels=train.target_names\n",
    "    , yticklabels=train.target_names)\n",
    "\n",
    "#plotting heatmap\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
